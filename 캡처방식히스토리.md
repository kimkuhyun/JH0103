# JH0103 v4.0 캡처 방식 진화 과정

## 개요
JH0103 프로젝트의 공고 캡처 시스템이 3단계로 진화한 과정을 코드 기반으로 정리한 문서입니다.

---

## 1단계: 초기 수동 캡처 방식 (2026-01-08)

### 커밋 히스토리
- **908e871** (2026-01-08): "익스텐션 추가 및 ai서버 폴더 추가"
- **ca6369c** (2026-01-08): "리사이징 사이즈 640으로 변경 및 프롬프트 제약 추가"

### 특징
- 사용자가 직접 스크린샷을 캡처하여 업로드
- Extension에 자동 캡처 기능 없음
- 수동으로 이미지를 받아 AI 서버로 전송하는 단순한 구조

### 한계점
- 사용자 개입 필요
- 캡처 범위 제어 어려움
- 일관성 없는 데이터 수집

---

## 2단계: 스크롤 기반 다중 스크린샷 자동 캡처 (메인 브랜치)

### 커밋 정보
- **63b17f0** (2026-01-10 06:47:23): "feat: implement one-click job posting capture system"
- **36ebf4f** (2026-01-10): "이미지 병합 기능 및 단일 이미지 분석 방식 구현"

### Extension 구현 (background.js)

#### 캡처 방식
```javascript
async function captureJobPosting(tabId, pageInfo) {
    const images = [];
    const { containerTop, containerHeight, viewportHeight, captureCount, currentScrollY } = pageInfo;
    
    // 컨테이너 시작 위치로 스크롤
    await chrome.tabs.sendMessage(tabId, { 
        action: 'SCROLL_TO', 
        position: containerTop 
    });
    
    // 컨테이너 영역만 캡처
    for (let i = 0; i < captureCount; i++) {
        const scrollPosition = containerTop + (i * viewportHeight);
        
        // 스크롤 및 캡처
        await chrome.tabs.sendMessage(tabId, { 
            action: 'SCROLL_TO', 
            position: scrollPosition 
        });
        await sleep(400);
        
        const dataUrl = await chrome.tabs.captureVisibleTab(tab.windowId, { 
            format: 'png' 
        });
        images.push(dataUrl.split(',')[1]); // Base64만 추출
    }
    
    // 원래 위치로 복원
    await chrome.tabs.sendMessage(tabId, { 
        action: 'SCROLL_TO', 
        position: currentScrollY 
    });
    
    return images; // 다중 이미지 배열 반환
}
```

**핵심 API**: `chrome.tabs.captureVisibleTab`
- 가시 영역만 캡처 가능
- 스크롤하며 최대 10장의 PNG 스크린샷 생성
- 각 이미지를 배열에 저장

#### Content Script (content.js)

**공고 끝 지점 감지**
```javascript
function findJobBoundaries() {
    const endMarkers = {
        wanted: ['[class*="ApplyButton"]', '[class*="SimilarJob"]'],
        jobkorea: ['.btnApply', '.sameWork'],
        saramin: ['.btn_apply', '.related_jobs']
    };
    
    // 끝 지점 감지 로직
    const containerHeight = endY ? endY - containerTop : container.scrollHeight * 0.8;
    
    // 최대 높이 제한: 15화면
    return Math.min(containerHeight, window.innerHeight * 15);
}
```

**불필요 요소 숨김**
```javascript
function hideUnnecessaryElements() {
    // display: none으로 숨김
    const trashSelectors = SITE_CONFIG[site].trash;
    trashSelectors.forEach(selector => {
        document.querySelectorAll(selector).forEach(el => {
            el.style.display = 'none';
        });
    });
}
```

**메타데이터 추출**
```javascript
function extractMetadata() {
    return {
        company: "...",
        title: "...",
        salary: "...",
        location: "...",
        deadline: "...",
        company_description: "...",
        employee_count: "...",
        raw_text: "..." // 최대 5000자
    };
}
```

#### 서버 전송 데이터
```javascript
{
    url: job.url,
    images: [base64_1, base64_2, ..., base64_N], // PNG 배열
    metadata: {
        company, title, salary, location, deadline,
        company_description, employee_count, raw_text
    }
}
```

### AI Engine 구현 (server.py)

#### 이미지 병합 처리
```python
def merge_images_vertically(base64_images):
    """모든 이미지를 세로로 이어붙여 단일 이미지 생성"""
    images = [Image.open(io.BytesIO(base64.b64decode(img))) for img in base64_images]
    
    # 동일 너비로 리사이즈
    target_width = min(max_width, MAX_WIDTH)
    resized_images = [img.resize((target_width, new_height)) for img in images]
    
    # 세로로 병합
    total_height = sum(img.height for img in resized_images)
    merged = Image.new('RGB', (target_width, total_height))
    
    y_offset = 0
    for img in resized_images:
        merged.paste(img, (0, y_offset))
        y_offset += img.height
    
    return merged
```

#### 분석 플로우
```python
@app.route('/analyze', methods=['POST'])
def analyze():
    data = request.get_json()
    images = data.get('images', [])  # 다중 이미지 수신
    
    # 이미지 병합
    merged_image = merge_images_vertically(images)
    
    # 단일 이미지로 분석 (동기)
    result = analyze_with_vision_model(merged_image, prompt)
    
    # 파일명: {회사명}_{제목}_{타임스탬프}.json
    filename = f"{company}_{title}_{timestamp}.json"
    
    return jsonify(result)
```

### 장점
- 원클릭 자동 캡처
- 추천공고 일부 제외 가능 (endMarkers + 80% 제한)
- 풍부한 메타데이터 추출

### 한계점
- **추천공고 혼입 문제**: endMarkers가 없으면 80% 제한에 의존, 불완전한 제거
- **다중 이미지 처리**: 서버에서 병합 과정 필요, 메모리 사용 증가
- **스크롤 기반**: 가시 영역만 캡처 가능, 여러 번 캡처 필요

---

## 3단계: CDP Bounds 기반 단일 영역 자동 캡처 (fix/image-processing-and-metadata 브랜치)

### 커밋 정보
- **1ad2cc6** (2026-01-10 13:11:34): "docs: 개선 사항 및 Docker 재빌드 가이드 추가"

### Extension 구현 (background.js)

#### 캡처 방식
```javascript
async function captureFullPage(tabId, bounds) {
    // Chrome DevTools Protocol 사용
    await chrome.debugger.attach({ tabId }, "1.3");
    
    try {
        const { data } = await chrome.debugger.sendCommand(
            { tabId },
            "Page.captureScreenshot",
            {
                format: "jpeg",
                quality: 80,
                captureBeyondViewport: true, // 스크롤 없이 전체 영역 캡처
                clip: {
                    x: bounds.x,
                    y: bounds.y,
                    width: bounds.width,
                    height: bounds.height,
                    scale: 1
                }
            }
        );
        
        return data; // Base64 JPEG
        
    } finally {
        await chrome.debugger.detach({ tabId });
    }
}
```

**핵심 차이점**:
- `chrome.debugger` API 사용
- `Page.captureScreenshot` 명령으로 **단일 이미지** 직접 캡처
- `captureBeyondViewport: true`로 스크롤 없이 전체 영역 캡처
- `clip` 파라미터로 정확한 영역 지정

#### 상태 폴링 시스템
```javascript
async function pollStatus(jobId) {
    const maxAttempts = 60; // 60초 타임아웃
    
    for (let i = 0; i < maxAttempts; i++) {
        const response = await fetch(`http://localhost:5000/status/${jobId}`);
        const result = await response.json();
        
        if (result.status === 'success') {
            return { success: true, data: result.data };
        } else if (result.status === 'error') {
            return { success: false, message: result.message };
        }
        
        await sleep(1000); // 1초 대기
    }
    
    throw new Error('분석 타임아웃');
}
```

#### Content Script (content.js)

**메인 콘텐츠 영역 지정**
```javascript
const SITE_CONFIG = {
    saramin: {
        mainSelector: 'section[class*="jview-0-"]', // 메인 콘텐츠만
        trash: ['.jview_header', '.starRate', '.aside_wrap', ...]
    },
    jobkorea: {
        mainSelector: '#container',
        trash: ['.sameWork', '.rdContent', ...]
    },
    wanted: {
        mainSelector: '.JobContent_JobContent__Qb6DR',
        trash: [
            '.JobAssociated_JobAssociated__XGF86', // 추천공고 완전 제거
            '[class*="RelatedJobs"]',
            ...
        ]
    }
};
```

**정확한 Bounds 계산**
```javascript
function getMainContentBounds() {
    const site = detectSite();
    const mainSelector = SITE_CONFIG[site].mainSelector;
    const mainEl = document.querySelector(mainSelector);
    
    if (!mainEl) {
        throw new Error('메인 콘텐츠를 찾을 수 없습니다');
    }
    
    const rect = mainEl.getBoundingClientRect();
    
    return {
        x: rect.left,
        y: rect.top + window.scrollY, // 절대 좌표
        width: rect.width,
        height: rect.height
    };
}
```

**변경 사항**:
- `findJobBoundaries()` 제거 → `getMainContentBounds()`로 대체
- endMarkers 로직 완전 제거
- wanted trash에 `.JobAssociated_JobAssociated__XGF86` 추가 (추천공고 섹션)
- Toast 시스템 제거
- iframe 중복 실행 방지: `window !== window.top` 체크

#### 서버 전송 데이터
```javascript
{
    pdf: single_base64_image, // JPEG, 단일 이미지
    metadata: {
        url: tab.url
    },
    url: tab.url
}
```

**변경 사항**:
- `images` 배열 → `pdf` 단일 이미지
- metadata에서 raw_text 제외, url만 전송

### AI Engine 구현 (server.py)

#### 비동기 처리 시스템
```python
import queue
import threading

job_queue = queue.Queue()
job_results = {}

def worker():
    """백그라운드 워커 스레드"""
    while True:
        job_id, image_data, url, metadata = job_queue.get()
        
        try:
            job_results[job_id] = {'status': 'processing'}
            
            # 이미지 최적화
            optimized_image = optimize_image(image_data)
            
            # 분석
            result = analyze_with_vision_model(optimized_image, url, metadata)
            
            # 파일 저장
            filename = sanitize_filename(result['title']) + '.json'
            save_result(filename, result)
            
            job_results[job_id] = {'status': 'success', 'data': result}
            
        except Exception as e:
            job_results[job_id] = {'status': 'error', 'message': str(e)}
        
        finally:
            job_queue.task_done()

# 워커 스레드 시작
threading.Thread(target=worker, daemon=True).start()
```

#### API 엔드포인트
```python
@app.route('/analyze', methods=['POST'])
def analyze():
    """분석 요청 - 즉시 job_id 반환"""
    data = request.get_json()
    image_data = data.get('pdf')  # 단일 이미지
    metadata = data.get('metadata', {})
    url = data.get('url', '')
    
    job_id = str(uuid.uuid4())
    job_queue.put((job_id, image_data, url, metadata))
    
    return jsonify({
        'status': 'queued',
        'job_id': job_id
    })

@app.route('/status/<job_id>', methods=['GET'])
def get_status(job_id):
    """분석 상태 확인"""
    if job_id not in job_results:
        return jsonify({'status': 'not_found'}), 404
    
    return jsonify(job_results[job_id])
```

#### 이미지 최적화
```python
IMAGE_CONFIG = {
    'MAX_WIDTH': 1000,
    'QUALITY': 80,
    'FORMAT': 'JPEG'
}

def optimize_image(base64_str):
    """단일 이미지 리사이징"""
    image_data = base64.b64decode(base64_str)
    img = Image.open(io.BytesIO(image_data))
    
    # 너비만 제한 (세로 길이는 전체 유지)
    if img.width > IMAGE_CONFIG['MAX_WIDTH']:
        ratio = IMAGE_CONFIG['MAX_WIDTH'] / img.width
        new_height = int(img.height * ratio)
        img = img.resize((IMAGE_CONFIG['MAX_WIDTH'], new_height))
    
    # JPEG 변환
    buffer = io.BytesIO()
    img.save(buffer, format=IMAGE_CONFIG['FORMAT'], quality=IMAGE_CONFIG['QUALITY'])
    
    return base64.b64encode(buffer.getvalue()).decode()
```

**변경 사항**:
- `merge_images_vertically()` 완전 제거
- 단일 이미지 직접 처리
- MAX_WIDTH 1000으로 리사이징
- 세로 길이 제한 없음 (전체 내용 유지)

#### 파일명 생성
```python
def sanitize_filename(title):
    """안전한 파일명 생성"""
    # 영문, 한글, 숫자, 공백, 하이픈, 언더스코어만 허용
    safe_title = re.sub(r'[^\w\s가-힣-]', '', title)
    
    # 연속 공백 → 단일 공백
    safe_title = re.sub(r'\s+', ' ', safe_title).strip()
    
    # 최대 100자
    if len(safe_title) > 100:
        safe_title = safe_title[:100]
    
    return safe_title

# 파일명: {공고타이틀}.json
# 중복 시: {공고타이틀}_1.json, {공고타이틀}_2.json
```

#### 모델 설정
```python
MODEL_CONFIG = {
    'model': 'llama3.2-vision',
    'num_ctx': 6000,
    'num_batch': 256,
    'temperature': 0,
    'timeout': 120
}
```

### 장점
1. **추천공고 100% 제거**: mainSelector로 정확한 영역만 캡처
2. **단일 캡처**: CDP로 한 번에 전체 영역 캡처, 스크롤 불필요
3. **메모리 최적화**: 병합 과정 없음, 단일 이미지 처리
4. **비동기 처리**: 즉시 응답, 백그라운드 분석
5. **가독성**: 공고 타이틀 기반 파일명

### 주요 개선 효과
- 메인 브랜치: 10장 캡처 → 서버 병합 → 분석 (동기)
- 현재 브랜치: 1장 캡처 → 직접 분석 (비동기)

---

## 비교 요약표

| 항목 | 1단계: 수동 | 2단계: 스크롤 기반 | 3단계: CDP Bounds |
|------|-------------|-------------------|-------------------|
| **캡처 방식** | 사용자 수동 | `captureVisibleTab` | `Page.captureScreenshot` |
| **캡처 횟수** | 1회 (사용자) | 10회 (자동) | 1회 (자동) |
| **API** | - | Chrome Tabs API | Chrome DevTools Protocol |
| **스크롤** | 필요 없음 | 필요 (10회) | 필요 없음 |
| **이미지 수** | 1개 | 10개 (PNG) | 1개 (JPEG) |
| **서버 처리** | 직접 분석 | 병합 → 분석 | 직접 분석 |
| **응답 방식** | 동기 | 동기 | 비동기 (폴링) |
| **추천공고 제거** | 수동 | 불완전 (80%) | 완벽 (100%) |
| **메타데이터** | - | 풍부 (8개 필드) | 최소 (url만) |
| **파일명** | - | {회사}_{제목}_{시간} | {제목}.json |
| **메모리 사용** | 낮음 | 높음 (병합) | 낮음 |
| **Toast** | - | 있음 | 없음 |

---

## 주요 커밋 타임라인

```
2026-01-08  908e871  [1단계] 익스텐션 및 AI 서버 초기 추가 (수동 캡처)
2026-01-08  ca6369c  리사이징 640 변경, 프롬프트 제약 추가
2026-01-10  63b17f0  [2단계] 원클릭 자동 캡처 시스템 구현 (스크롤 기반)
2026-01-10  36ebf4f  이미지 병합 기능 및 단일 이미지 분석 방식
2026-01-10  1ad2cc6  [3단계] CDP Bounds 기반 캡처로 개선
```

---

## 결론

JH0103 v4.0은 3단계에 걸쳐 진화했습니다:

1. **수동 캡처** → 사용자 개입 필요, 일관성 부족
2. **스크롤 기반 자동 캡처** → 원클릭 자동화, 추천공고 혼입 문제
3. **CDP Bounds 단일 캡처** → 완벽한 영역 지정, 최적화된 처리

특히 3단계에서는 Chrome DevTools Protocol을 활용하여 정확한 영역만 한 번에 캡처함으로써, 추천공고 혼입 문제를 완전히 해결하고 처리 효율을 극대화했습니다.
<img width="1316" height="106" alt="image" src="https://github.com/user-attachments/assets/09db1bb8-9d49-4971-a026-be04d25be58c" />
현재 처리시간 약 1분으로 처리시간 30초 이내로 단축이 목표
